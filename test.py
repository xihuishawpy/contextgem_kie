import os
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import ContextGem components
from contextgem.public.documents import Document
from contextgem.public.llms import DocumentLLM
from contextgem.public.aspects import Aspect
from contextgem.public.concepts import StringConcept
from contextgem.public.images import Image

# Import PDF processing and LiteLLM
import litellm
from PIL import Image as PILImage
import fitz  # PyMuPDF for PDF to image conversion
import base64
import io

# Configure LiteLLM to use Qwen API
litellm.set_verbose = True

def convert_pdf_to_contextgem_images(pdf_path: str):
    """Convert PDF pages to ContextGem Image objects"""
    try:
        contextgem_images = []
        pdf_document = fitz.open(pdf_path)

        for page_num in range(len(pdf_document)):
            # Get the page
            page = pdf_document[page_num]

            # Convert page to image
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for better quality

            # Convert to PIL Image then to bytes
            img = PILImage.frombytes("RGB", [pix.width, pix.height], pix.samples)

            # Convert to bytes
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='PNG')
            img_bytes = img_byte_arr.getvalue()

            # Convert to base64
            base64_data = base64.b64encode(img_bytes).decode('utf-8')

            # Create ContextGem Image with correct parameters
            contextgem_img = Image(
                mime_type="image/png",
                base64_data=base64_data
            )
            contextgem_images.append(contextgem_img)

        pdf_document.close()
        return contextgem_images
    except Exception as e:
        print(f"PDFè½¬ContextGemå›¾åƒé”™è¯¯: {str(e)}")
        return None


def define_extraction_aspects():
    """Define the aspects and concepts for PDF extraction - focused on testing basis and results"""

    # Create aspect for testing basis and results extraction
    aspect = Aspect(
        name="æ£€æµ‹ä¾æ®ä¸ç»“æœæå–",
        description="ä¸“é—¨æå–æ–‡æ¡£ä¸­æ‰€æœ‰ä¸æ£€æµ‹ä¾æ®ï¼ˆæ ‡å‡†ã€è§„èŒƒã€æ–¹æ³•ï¼‰å’Œæ£€æµ‹ç»“æœï¼ˆæ•°æ®ã€ç»“è®ºã€å‚æ•°ï¼‰ç›¸å…³çš„å†…å®¹",
        concepts=[
            StringConcept(
                name="æ£€æµ‹ä¾æ®",
                description="æ–‡æ¡£ä¸­æåˆ°çš„æ‰€æœ‰æ£€æµ‹æ ‡å‡†ã€è§„èŒƒã€æ–¹æ³•ã€è§„ç¨‹ç­‰ä¾æ®æ€§æ–‡ä»¶å’Œæ¡æ¬¾"
            ),
            StringConcept(
                name="æ£€æµ‹æ ‡å‡†",
                description="å…·ä½“çš„å›½å®¶æ ‡å‡†ã€è¡Œä¸šæ ‡å‡†ã€åœ°æ–¹æ ‡å‡†æˆ–ä¼ä¸šæ ‡å‡†ç­‰æ£€æµ‹æ ‡å‡†ä¿¡æ¯"
            ),
            StringConcept(
                name="æ£€æµ‹æ–¹æ³•",
                description="ä½¿ç”¨çš„å…·ä½“æ£€æµ‹æ–¹æ³•ã€æµ‹é‡æ–¹æ³•ã€è¯•éªŒæ–¹æ³•ç­‰"
            ),
            StringConcept(
                name="æ£€æµ‹ç»“æœ",
                description="æ‰€æœ‰çš„æ£€æµ‹ç»“æœæ•°æ®ã€æµ‹é‡æ•°æ®ã€æµ‹è¯•æ•°æ®ç­‰å®šé‡æˆ–å®šæ€§ç»“æœ"
            ),
            StringConcept(
                name="æ£€æµ‹æ•°æ®",
                description="å…·ä½“çš„æ•°å€¼æ£€æµ‹ç»“æœï¼ŒåŒ…æ‹¬æµ‹é‡å€¼ã€è¯¯å·®ã€ä¸ç¡®å®šåº¦ç­‰"
            ),
            StringConcept(
                name="æ£€æµ‹ç»“è®º",
                description="åŸºäºæ£€æµ‹ç»“æœå¾—å‡ºçš„ç»“è®ºã€åˆ¤å®šã€è¯„ä¼°æ„è§ç­‰"
            ),
            StringConcept(
                name="æ£€æµ‹å‚æ•°",
                description="æ£€æµ‹è¿‡ç¨‹ä¸­æ¶‰åŠçš„å„ç§æŠ€æœ¯å‚æ•°ã€æ¡ä»¶å‚æ•°ç­‰"
            ),
            StringConcept(
                name="è®¾å¤‡ä¿¡æ¯",
                description="æ£€æµ‹ç”¨è®¾å¤‡çš„å‹å·ã€è§„æ ¼ã€ç¼–å·ç­‰ä¿¡æ¯"
            )
        ],
        llm_role="extractor_text",
        reference_depth="paragraphs",
        add_justifications=True,
        justification_depth="brief"
    )

    return aspect

async def extract_content_with_two_step(pdf_path: str):
    """Two-step extraction: Qwen VL OCR + ContextGem structured extraction"""
    try:
        # Step 1: Use Qwen VL for OCR to extract text
        print("=== æ­¥éª¤1: ä½¿ç”¨Qwen VLè¿›è¡Œæ–‡å­—æå– ===")
        ocr_text = await extract_pdf_text_with_vision_ocr_simple(pdf_path)

        if not ocr_text:
            raise ValueError("æ–‡å­—æå–å¤±è´¥ï¼Œæ— æ³•è·å¾—æ–‡æœ¬å†…å®¹")

        print(f"æ–‡å­—æå–å®Œæˆï¼Œå…± {len(ocr_text)} å­—ç¬¦")

        # Step 2: Use ContextGem for structured extraction
        print("\n=== æ­¥éª¤2: ä½¿ç”¨ContextGemè¿›è¡Œç»“æ„åŒ–æå– ===")

        # Create document from OCR text
        print("æ­£åœ¨åˆ›å»ºContextGemæ–‡æ¡£å¯¹è±¡...")
        document = Document(raw_text=ocr_text)
        print(f"æ–‡æ¡£å¯¹è±¡åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {len(document.paragraphs)} ä¸ªæ®µè½")

        # Define extraction aspects
        print("æ­£åœ¨å®šä¹‰æå–è§„åˆ™...")
        aspect = define_extraction_aspects()

        # Create ContextGem LLM for text extraction
        print("æ­£åœ¨é…ç½®ContextGemæ–‡æœ¬æ¨¡å‹...")
        llm = create_qwen_vl_llm()

        # Assign aspect to document
        document = document.clone()
        document.add_aspects([aspect])

        # Use ContextGem's structured extraction
        print("å¼€å§‹æ‰§è¡ŒContextGemç»“æ„åŒ–æå–...")
        try:
            result = await llm.extract_aspects_from_document_async(document)
            print("ContextGemæå–æ“ä½œå®Œæˆ")

            # Display results
            print("\n=== ä¸¤æ­¥ç»“æ„åŒ–æå–ç»“æœ ===")
            print(f"å¤„ç†çš„æ–‡ä»¶: {pdf_path}")
            print(f"æå–çš„æ–¹é¢: {aspect.name}")
            print("-" * 60)

            # Get the processed aspect from result
            processed_aspect = result[0] if result else aspect

            # Display extracted items
            extracted_items = processed_aspect.extracted_items
            print(f"æå–åˆ°çš„é¡¹ç›®æ•°é‡: {len(extracted_items)}")

            if extracted_items:
                print(f"æˆåŠŸæå–åˆ° {len(extracted_items)} é¡¹ç»“æ„åŒ–ä¿¡æ¯ï¼š")

                # Group by concept for better organization
                concept_groups = {}
                for item in extracted_items:
                    if hasattr(item, 'concept') and hasattr(item.concept, 'name'):
                        concept_name = item.concept.name
                    else:
                        concept_name = 'æœªçŸ¥æ¦‚å¿µ'

                    if concept_name not in concept_groups:
                        concept_groups[concept_name] = []
                    concept_groups[concept_name].append(item)

                # Display each concept group
                for concept_name, items in concept_groups.items():
                    print(f"\nğŸ“‹ {concept_name}:")
                    print("-" * 40)
                    for i, item in enumerate(items, 1):
                        value = getattr(item, 'value', str(item))
                        justification = getattr(item, 'justification', None)

                        print(f"{i}. {value}")
                        if justification:
                            print(f"   ç†ç”±: {justification}")
                        print()
            else:
                print("ContextGemæœªæå–åˆ°ç»“æ„åŒ–ä¿¡æ¯")

            print("-" * 60)
            return result

        except Exception as extract_error:
            print(f"ContextGemæå–å¤±è´¥: {str(extract_error)}")
            return None

    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def create_qwen_vl_llm():
    """Create a Qwen VL (Vision) LLM configuration using LiteLLM"""
    api_key = os.getenv("DASHSCOPE_API_KEY")
    base_url = os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")

    if not api_key:
        raise ValueError("DASHSCOPE_API_KEY not found in environment variables")

    # Create LLM configuration for ContextGem using Qwen VL
    llm = DocumentLLM(
        model="dashscope/qwen-vl-plus",  # Qwen VL model
        api_key=api_key,
        api_base=base_url,
        temperature=0.1,
        max_tokens=8000,
        role="extractor_text"  # Use text role - ContextGem will handle images automatically
    )

    # Manually set vision capability since LiteLLM doesn't detect it
    llm._supports_vision = True

    return llm

async def extract_pdf_text_with_vision_ocr_simple(pdf_path: str):
    """Simple OCR using Qwen VL to extract text from PDF images"""
    try:
        print(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {pdf_path}")

        # Convert PDF to ContextGem images
        print("æ­£åœ¨è½¬æ¢PDFä¸ºå›¾åƒ...")
        images = convert_pdf_to_contextgem_images(pdf_path)

        if not images:
            raise ValueError("æ— æ³•å°†PDFè½¬æ¢ä¸ºå›¾åƒ")

        print(f"æˆåŠŸè½¬æ¢PDFä¸º {len(images)} å¼ å›¾åƒ")

        # Create Qwen VL LLM for simple OCR
        print("æ­£åœ¨é…ç½®Qwen VLæ¨¡å‹è¿›è¡Œæ–‡å­—æå–...")
        llm = create_qwen_vl_llm()

        # Process all images at once for OCR (simpler approach)
        ocr_prompt = """
è¯·ä»è¿™äº›æ£€æµ‹æŠ¥å‘Šå›¾åƒä¸­æå–æ‰€æœ‰æ–‡å­—å†…å®¹ã€‚

è¦æ±‚ï¼š
1. æå–æ‰€æœ‰æ–‡å­—ï¼Œä¿æŒåŸå§‹æ ¼å¼
2. è¯†åˆ«è¡¨æ ¼ä¸­çš„æ•°æ®
3. ä¿æŒæ•°å­—ã€ç¬¦å·ã€å•ä½ç­‰
4. æŒ‰ç…§é¡µé¢é¡ºåºæ•´ç†å†…å®¹

è¯·å®Œæ•´æå–æ–‡å­—å†…å®¹ï¼Œä¸è¦é—æ¼ä»»ä½•ä¿¡æ¯ã€‚
"""

        try:
            # Use Qwen VL for direct text extraction
            result = await llm.chat_async(ocr_prompt, images=images)

            print(f"\n=== PDF OCRæ–‡å­—æå–å®Œæˆ ===")
            print(f"å¤„ç†é¡µæ•°: {len(images)}")
            print(f"æå–æ–‡æœ¬é•¿åº¦: {len(result)} å­—ç¬¦")
            print("-" * 40)
            print("æå–çš„å‰200ä¸ªå­—ç¬¦:")
            print(result[:200] + "..." if len(result) > 200 else result)
            print("-" * 40)

            return result

        except Exception as extract_error:
            print(f"OCRæå–å¤±è´¥: {str(extract_error)}")
            return None

    except Exception as e:
        print(f"OCRå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """Main function to run PDF extraction using Qwen VL + ContextGem two-step approach"""

    # PDF file path
    pdf_path = "A224005962110101E.pdf"

    # Check if file exists
    if not Path(pdf_path).exists():
        print(f"é”™è¯¯: PDFæ–‡ä»¶ '{pdf_path}' ä¸å­˜åœ¨")
        return

    # Run extraction
    print("=== Qwen VL OCR + ContextGem ä¸¤æ­¥ç»“æ„åŒ–æå–å·¥å…· ===")

    try:
        # Run the async function
        import asyncio
        result = asyncio.run(extract_content_with_two_step(pdf_path))

        if result:
            print("âœ… ä¸¤æ­¥ç»“æ„åŒ–æå–å®Œæˆï¼")
        else:
            print("âŒ ä¸¤æ­¥ç»“æ„åŒ–æå–å¤±è´¥ï¼")

    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
